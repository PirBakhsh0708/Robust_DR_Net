{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea08d67",
   "metadata": {},
   "source": [
    "### Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1beadc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.12/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import os, random, torch, cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, \\\n",
    "    roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, densenet121, efficientnet_b7, \\\n",
    "    inception_v3, convnext_tiny\n",
    "from torchvision.models import ResNet50_Weights, DenseNet121_Weights, \\\n",
    "    EfficientNet_B7_Weights, Inception_V3_Weights, ConvNeXt_Tiny_Weights\n",
    "\n",
    "# Device config\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMG_SIZE = 224  # Adaptable for each model\n",
    "NUM_CLASSES = 5\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97de3ab",
   "metadata": {},
   "source": [
    "### Dataset + Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff40fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class APTOSDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.loc[idx, 'id_code']\n",
    "        label = int(self.df.loc[idx, 'diagnosis'])\n",
    "        image_path = os.path.join(self.image_dir, f\"{img_id}.png\")\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "# Example transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b6e53",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e345fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"Dataset/train_1.csv\")\n",
    "val_df = pd.read_csv(\"Dataset/valid.csv\")\n",
    "\n",
    "train_dataset = APTOSDataset(train_df, \"Dataset/train_images\",\n",
    "                             transform=train_transforms)\n",
    "val_dataset = APTOSDataset(val_df, \"Dataset/val_images\",\n",
    "                           transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844fd113",
   "metadata": {},
   "source": [
    "### Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff57d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.functional.cross_entropy(inputs, targets,\n",
    "                                              reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            loss = self.alpha[targets] * loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2038c692",
   "metadata": {},
   "source": [
    "### Model Wrapper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada1ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name):\n",
    "    if name == \"resnet50\":\n",
    "        model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    \n",
    "    elif name == \"resnet34\":\n",
    "        model = resnet50(weights=ResNet34_Weights.DEFAULT)\n",
    "        model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "    elif name == \"densenet121\":\n",
    "        model = densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "        model.classifier = nn.Linear(model.classifier.in_features,\n",
    "                                     NUM_CLASSES)\n",
    "\n",
    "    elif name == \"efficientnet_b7\":\n",
    "        model = efficientnet_b7(weights=EfficientNet_B7_Weights.DEFAULT)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features,\n",
    "                                        NUM_CLASSES)\n",
    "\n",
    "    elif name == \"inception_v3\":\n",
    "        model = inception_v3(weights=Inception_V3_Weights.DEFAULT,\n",
    "                             aux_logits=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "    elif name == \"convnext_tiny\":\n",
    "        model = convnext_tiny(weights=ConvNeXt_Tiny_Weights.DEFAULT)\n",
    "        model.classifier[2] = nn.Linear(model.classifier[2].in_features,\n",
    "                                        NUM_CLASSES)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model name\")\n",
    "\n",
    "    return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7e70e1",
   "metadata": {},
   "source": [
    "### Training & Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e70288fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, correct = 0.0, 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    return total_loss / len(loader.dataset), \\\n",
    "           correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc76f4",
   "metadata": {},
   "source": [
    "### Validate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fa87826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0.0, 0\n",
    "    all_labels, all_preds, all_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validating\",\n",
    "                                   leave=False):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    acc = correct / len(loader.dataset)\n",
    "    auc = roc_auc_score(\n",
    "        label_binarize(all_labels, classes=np.arange(NUM_CLASSES)),\n",
    "        all_probs,\n",
    "        multi_class='ovr'\n",
    "    )\n",
    "    report = classification_report(all_labels, all_preds, digits=4)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    return total_loss / len(loader.dataset), acc, auc, report, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d3b8c3",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f808067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, \\\n",
    "    roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2003ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision.models import resnet50, ResNet50_Weights, densenet121, \\\n",
    "    DenseNet121_Weights\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import (\n",
    "    cohen_kappa_score, matthews_corrcoef,\n",
    "    roc_auc_score, precision_recall_curve, auc,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5d1d8",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "921fbcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_extra_metrics(all_labels, all_preds, all_probs, num_classes):\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    kappa = cohen_kappa_score(all_labels, all_preds, weights='quadratic')\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "    y_true_bin = label_binarize(all_labels,\n",
    "                                classes=np.arange(num_classes))\n",
    "\n",
    "    auc_macro = roc_auc_score(y_true_bin, all_probs,\n",
    "                              average='macro', multi_class='ovr')\n",
    "    auc_micro = roc_auc_score(y_true_bin, all_probs,\n",
    "                              average='micro', multi_class='ovr')\n",
    "    auc_weighted = roc_auc_score(y_true_bin, all_probs,\n",
    "                                 average='weighted', multi_class='ovr')\n",
    "\n",
    "    pr_aucs = []\n",
    "    for i in range(num_classes):\n",
    "        precision, recall, _ = precision_recall_curve(y_true_bin[:, i],\n",
    "                                                      all_probs[:, i])\n",
    "        pr_aucs.append(auc(recall, precision))\n",
    "    auprc_macro = np.mean(pr_aucs)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sensitivity = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    specificity = []\n",
    "    for i in range(num_classes):\n",
    "        tn = cm.sum() - (cm[i, :].sum() +\n",
    "                         cm[:, i].sum() -\n",
    "                         cm[i, i])\n",
    "        fp = cm[:, i].sum() - cm[i, i]\n",
    "        specificity.append(tn / (tn + fp))\n",
    "\n",
    "    return {\n",
    "        \"Kappa\": kappa,\n",
    "        \"MCC\": mcc,\n",
    "        \"AUC_Macro\": auc_macro,\n",
    "        \"AUC_Micro\": auc_micro,\n",
    "        \"AUC_Weighted\": auc_weighted,\n",
    "        \"AUPRC_Macro\": auprc_macro,\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda5991",
   "metadata": {},
   "source": [
    "### Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e03084d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "\n",
    "# Assuming your labels are in train_df['diagnosis']\n",
    "labels = train_df['diagnosis'].values\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "\n",
    "class_weights = torch.tensor(class_weights,\n",
    "                             dtype=torch.float32).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3d630",
   "metadata": {},
   "source": [
    "### Imports and Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ad6825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from sklearn.metrics import classification_report, confusion_matrix, \\\n",
    "    roc_auc_score, matthews_corrcoef, cohen_kappa_score, \\\n",
    "    precision_recall_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup\n",
    "NUM_CLASSES = 5\n",
    "NUM_EPOCHS=10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load ResNet50\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=1e-4,\n",
    "                              weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0241e10",
   "metadata": {},
   "source": [
    "### TRAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "772123b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, correct = 0.0, 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = correct / len(loader.dataset)\n",
    "\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f35af",
   "metadata": {},
   "source": [
    "### VALIDATION LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e221e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0.0, 0\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = correct / len(loader.dataset)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "    auc_score = roc_auc_score(y_true_bin, np.array(y_probs),\n",
    "                              multi_class='ovr')\n",
    "\n",
    "    report = classification_report(y_true, y_pred, digits=4)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return avg_loss, acc, auc_score, report, cm, \\\n",
    "           y_true, y_pred, y_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da29625",
   "metadata": {},
   "source": [
    "### METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d4e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, y_probs):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "\n",
    "    kappa = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    macro_auc = roc_auc_score(y_true_bin, y_probs,\n",
    "                              average='macro', multi_class='ovr')\n",
    "    micro_auc = roc_auc_score(y_true_bin, y_probs,\n",
    "                              average='micro', multi_class='ovr')\n",
    "    weighted_auc = roc_auc_score(y_true_bin, y_probs,\n",
    "                                 average='weighted', multi_class='ovr')\n",
    "\n",
    "    pr_aucs = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        precision, recall, _ = precision_recall_curve(y_true_bin[:, i],\n",
    "                                                      y_probs[:, i])\n",
    "        pr_aucs.append(auc(recall, precision))\n",
    "\n",
    "    auprc_macro = np.mean(pr_aucs)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    specificity = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
    "        fp = cm[:, i].sum() - cm[i, i]\n",
    "        specificity.append(tn / (tn + fp))\n",
    "\n",
    "    return {\n",
    "        \"Cohen_Kappa\": kappa,\n",
    "        \"MCC\": mcc,\n",
    "        \"AUC_Macro\": macro_auc,\n",
    "        \"AUC_Micro\": micro_auc,\n",
    "        \"AUC_Weighted\": weighted_auc,\n",
    "        \"AUPRC_Macro\": auprc_macro,\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"Confusion_Matrix\": cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c13cdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8eee287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.0000 --> 0.7678), saving model\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.7678 --> 0.8197), saving model\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.8197 --> 0.8415), saving model\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.8415 --> 0.8525), saving model\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model saved to: saved_models/best_model_resnet50.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "best_model_path = \"saved_models/best_model_resnet50.pth\"\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc, val_auc, report, cm, \\\n",
    "    y_true, y_pred, y_probs = validate(\n",
    "        model, val_loader, criterion\n",
    "    )\n",
    "\n",
    "    metrics = compute_metrics(y_true, y_pred, y_probs)\n",
    "\n",
    "    # Save model if validation accuracy improves\n",
    "    if val_acc > best_val_acc:\n",
    "        print(f\"Validation accuracy improved \"\n",
    "              f\"({best_val_acc:.4f} --> {val_acc:.4f}), saving model\")\n",
    "\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "print(f\"\\nBest model saved to: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f605c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import (\n",
    "    cohen_kappa_score, matthews_corrcoef, roc_auc_score,\n",
    "    precision_recall_curve, auc, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup\n",
    "NUM_CLASSES = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load DenseNet121\n",
    "model = densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0527ba",
   "metadata": {},
   "source": [
    "### Train One epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab85fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, correct = 0.0, 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = correct / len(loader.dataset)\n",
    "    return avg_loss, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8ca67",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65670708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0.0, 0\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = correct / len(loader.dataset)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "    auc_score = roc_auc_score(y_true_bin, np.array(y_probs),\n",
    "                              multi_class='ovr')\n",
    "\n",
    "    report = classification_report(y_true, y_pred, digits=4)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return avg_loss, acc, auc_score, report, cm, y_true, y_pred, y_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea3b07",
   "metadata": {},
   "source": [
    "### Metrics computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9b5cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, y_probs):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "\n",
    "    kappa = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    macro_auc = roc_auc_score(y_true_bin, y_probs,\n",
    "                              average='macro', multi_class='ovr')\n",
    "    micro_auc = roc_auc_score(y_true_bin, y_probs,\n",
    "                              average='micro', multi_class='ovr')\n",
    "    weighted_auc = roc_auc_score(y_true_bin, y_probs,\n",
    "                                 average='weighted', multi_class='ovr')\n",
    "\n",
    "    pr_aucs = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        precision, recall, _ = precision_recall_curve(y_true_bin[:, i],\n",
    "                                                      y_probs[:, i])\n",
    "        pr_aucs.append(auc(recall, precision))\n",
    "\n",
    "    auprc_macro = np.mean(pr_aucs)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    specificity = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
    "        fp = cm[:, i].sum() - cm[i, i]\n",
    "        specificity.append(tn / (tn + fp))\n",
    "\n",
    "    return {\n",
    "        \"Cohen_Kappa\": kappa,\n",
    "        \"MCC\": mcc,\n",
    "        \"AUC_Macro\": macro_auc,\n",
    "        \"AUC_Micro\": micro_auc,\n",
    "        \"AUC_Weighted\": weighted_auc,\n",
    "        \"AUPRC_Macro\": auprc_macro,\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"Confusion_Matrix\": cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "119cb102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.0000 --> 0.7923); saving model.\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.7923 --> 0.8060); saving model.\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.8060 --> 0.8279); saving model.\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.8279 --> 0.8443); saving model.\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.8443 --> 0.8470); saving model.\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved to: best_model_densenet121.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "best_model_path = \"saved_models/best_model_densenet121.pth\"\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc, val_auc, report, cm, \\\n",
    "    y_true, y_pred, y_probs = validate(\n",
    "        model, val_loader, criterion\n",
    "    )\n",
    "\n",
    "    metrics = compute_metrics(y_true, y_pred, y_probs)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        print(f\"Validation accuracy improved \"\n",
    "              f\"({best_val_acc:.4f} --> {val_acc:.4f}); saving model.\")\n",
    "\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "print(f\"Best model saved to: {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6337925c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc583e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_673352/146715212.py:23: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, classification_report, confusion_matrix,\n",
    "    cohen_kappa_score, matthews_corrcoef, precision_recall_curve, auc\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83a077",
   "metadata": {},
   "source": [
    "### Efficientnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b38538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176ce9f",
   "metadata": {},
   "source": [
    "### Train One epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ea0ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, correct = 0.0, 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Mixed precision forward pass\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass with AMP\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        # memory cleanup\n",
    "        del images, labels, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = correct / len(loader.dataset)\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9385b36",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "511004bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0.0, 0\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = probs.argmax(dim=1)\n",
    "\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "            del images, labels, outputs, probs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = correct / len(loader.dataset)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "    auc_score = roc_auc_score(y_true_bin, np.array(y_probs), multi_class=\"ovr\")\n",
    "\n",
    "    report = classification_report(y_true, y_pred, digits=4)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return avg_loss, acc, auc_score, report, cm, y_true, y_pred, y_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93183a6e",
   "metadata": {},
   "source": [
    "### Metrics Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8aac52a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, y_probs):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "\n",
    "    kappa = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    macro_auc = roc_auc_score(y_true_bin, y_probs, average=\"macro\", multi_class=\"ovr\")\n",
    "    micro_auc = roc_auc_score(y_true_bin, y_probs, average=\"micro\", multi_class=\"ovr\")\n",
    "    weighted_auc = roc_auc_score(y_true_bin, y_probs, average=\"weighted\", multi_class=\"ovr\")\n",
    "\n",
    "    # PR AUC per class\n",
    "    pr_aucs = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        p, r, _ = precision_recall_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "        pr_aucs.append(auc(r, p))\n",
    "\n",
    "    auprc_macro = np.mean(pr_aucs)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    specificity = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
    "        fp = cm[:, i].sum() - cm[i, i]\n",
    "        specificity.append(tn / (tn + fp))\n",
    "\n",
    "    return {\n",
    "        \"Cohen_Kappa\": kappa,\n",
    "        \"MCC\": mcc,\n",
    "        \"AUC_Macro\": macro_auc,\n",
    "        \"AUC_Micro\": micro_auc,\n",
    "        \"AUC_Weighted\": weighted_auc,\n",
    "        \"AUPRC_Macro\": auprc_macro,\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"Confusion_Matrix\": cm,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9893901b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.0000 → 0.7568). Saving model...\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.7568 → 0.8197). Saving model...\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.8197 → 0.8333). Saving model...\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.8333 → 0.8443). Saving model...\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved to: best_model_efficientnet_b0_lowmem.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "best_model_path = \"saved_models/best_model_efficientnet_b0_lowmem.pth\"\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "\n",
    "    val_loss, val_acc, val_auc, report, cm, \\\n",
    "        y_true, y_pred, y_probs = validate(model, val_loader, criterion)\n",
    "\n",
    "    metrics = compute_metrics(y_true, y_pred, y_probs)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        print(f\"Validation accuracy improved ({best_val_acc:.4f} → {val_acc:.4f}). Saving model...\")\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "print(f\"Best model saved to: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e88de75",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c77678a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    matthews_corrcoef, cohen_kappa_score, precision_recall_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "IMG_SIZE = 299                       # IMPORTANT for Inception v3\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 8                       # Safe for 20GB GPUs\n",
    "NUM_EPOCHS = 10\n",
    "best_val_acc = 0\n",
    "best_model_path = \"best_inceptionv3.pth\"\n",
    "\n",
    "\n",
    "class APTOSDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.loc[idx, \"id_code\"]\n",
    "        label = int(self.df.loc[idx, \"diagnosis\"])\n",
    "\n",
    "        img_path = os.path.join(self.image_dir, f\"{img_id}.png\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77e50ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"Dataset/train_1.csv\")\n",
    "val_df   = pd.read_csv(\"Dataset/valid.csv\")\n",
    "\n",
    "train_dataset = APTOSDataset(train_df, \"Dataset/train_images\", train_transforms)\n",
    "val_dataset   = APTOSDataset(val_df,   \"Dataset/val_images\",   val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa67c23",
   "metadata": {},
   "source": [
    "### Inception_V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba895012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_673352/368626570.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)\n",
    "\n",
    "# Enable Aux logits\n",
    "model.aux_logits = True\n",
    "\n",
    "# Update classifier\n",
    "model.AuxLogits.fc = nn.Linear(model.AuxLogits.fc.in_features, NUM_CLASSES)\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "145f9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_logits(output):\n",
    "    \"\"\"\n",
    "    Handles Inception behavior:\n",
    "    - Training mode returns InceptionOutputs (with .logits + .aux_logits)\n",
    "    - Eval mode returns a plain tensor\n",
    "    \"\"\"\n",
    "    # In training mode: InceptionOutputs object\n",
    "    if hasattr(output, \"logits\"):\n",
    "        return output.logits\n",
    "\n",
    "    # Eval mode: plain tensor\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7f97f6",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4187d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, correct = 0.0, 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Main and auxiliary losses\n",
    "            loss1 = criterion(outputs.logits, labels)\n",
    "            loss2 = criterion(outputs.aux_logits, labels)\n",
    "\n",
    "            loss = loss1 + 0.4 * loss2\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        correct += (outputs.logits.argmax(1) == labels).sum().item()\n",
    "\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89db37b",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59ad5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0.0, 0\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            logits = extract_logits(outputs)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = correct / len(loader.dataset)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "    auc_score = roc_auc_score(y_true_bin, np.array(y_probs), multi_class=\"ovr\")\n",
    "\n",
    "    report = classification_report(y_true, y_pred, digits=4)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return avg_loss, acc, auc_score, report, cm, y_true, y_pred, y_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd59df2",
   "metadata": {},
   "source": [
    "### Metrics Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4de587f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, y_probs):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "\n",
    "    kappa = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    macro_auc = roc_auc_score(y_true_bin, y_probs, average='macro', multi_class='ovr')\n",
    "    micro_auc = roc_auc_score(y_true_bin, y_probs, average='micro', multi_class='ovr')\n",
    "    weighted_auc = roc_auc_score(y_true_bin, y_probs, average='weighted', multi_class='ovr')\n",
    "\n",
    "    pr_aucs = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "        pr_aucs.append(auc(recall, precision))\n",
    "\n",
    "    auprc_macro = np.mean(pr_aucs)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    specificity = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
    "        fp = cm[:, i].sum() - cm[i, i]\n",
    "        specificity.append(tn / (tn + fp))\n",
    "\n",
    "    return {\n",
    "        \"Cohen_Kappa\": kappa,\n",
    "        \"MCC\": mcc,\n",
    "        \"AUC_Macro\": macro_auc,\n",
    "        \"AUC_Micro\": micro_auc,\n",
    "        \"AUC_Weighted\": weighted_auc,\n",
    "        \"AUPRC_Macro\": auprc_macro,\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"Confusion_Matrix\": cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417298cd",
   "metadata": {},
   "source": [
    "### Saving Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1c8a1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== EPOCH 1/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                         | 0/367 [00:00<?, ?it/s]/tmp/ipykernel_673352/779262897.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6994 | Train Acc: 0.8164\n",
      "Val Loss: 0.5679 | Val Acc: 0.8060 | AUC: 0.9217\n",
      "Improved 0.0000 → 0.8060, saving model.\n",
      "\n",
      "===== EPOCH 2/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                         | 0/367 [00:00<?, ?it/s]/tmp/ipykernel_673352/779262897.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6437 | Train Acc: 0.8324\n",
      "Val Loss: 0.6150 | Val Acc: 0.8169 | AUC: 0.9174\n",
      "Improved 0.8060 → 0.8169, saving model.\n",
      "\n",
      "===== EPOCH 3/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                         | 0/367 [00:00<?, ?it/s]/tmp/ipykernel_673352/779262897.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6113 | Train Acc: 0.8399\n",
      "Val Loss: 0.5365 | Val Acc: 0.8142 | AUC: 0.9316\n",
      "\n",
      "===== EPOCH 4/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                         | 0/367 [00:00<?, ?it/s]/tmp/ipykernel_673352/779262897.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5054 | Train Acc: 0.8686\n",
      "Val Loss: 0.5124 | Val Acc: 0.8306 | AUC: 0.9426\n",
      "Improved 0.8169 → 0.8306, saving model.\n",
      "\n",
      "===== EPOCH 5/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                         | 0/367 [00:00<?, ?it/s]/tmp/ipykernel_673352/779262897.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4757 | Train Acc: 0.8761\n",
      "Val Loss: 0.4955 | Val Acc: 0.8470 | AUC: 0.9511\n",
      "Improved 0.8306 → 0.8470, saving model.\n",
      "\n",
      "===== EPOCH 6/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                         | 0/367 [00:00<?, ?it/s]/tmp/ipykernel_673352/779262897.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4639 | Train Acc: 0.8809\n",
      "Val Loss: 0.4683 | Val Acc: 0.8607 | AUC: 0.9510\n",
      "Improved 0.8470 → 0.8607, saving model.\n",
      "\n",
      "===== EPOCH 7/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                         | 0/367 [00:00<?, ?it/s]/tmp/ipykernel_673352/779262897.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3637 | Train Acc: 0.9075\n",
      "Val Loss: 0.4383 | Val Acc: 0.8525 | AUC: 0.9558\n",
      "\n",
      "===== EPOCH 8/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                         | 0/367 [00:00<?, ?it/s]/tmp/ipykernel_673352/779262897.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3404 | Train Acc: 0.9113\n",
      "Val Loss: 0.5523 | Val Acc: 0.8115 | AUC: 0.9471\n",
      "\n",
      "===== EPOCH 9/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                         | 0/367 [00:00<?, ?it/s]/tmp/ipykernel_673352/779262897.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3282 | Train Acc: 0.9150\n",
      "Val Loss: 0.7212 | Val Acc: 0.8197 | AUC: 0.9238\n",
      "\n",
      "===== EPOCH 10/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                         | 0/367 [00:00<?, ?it/s]/tmp/ipykernel_673352/779262897.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3091 | Train Acc: 0.9246\n",
      "Val Loss: 0.5548 | Val Acc: 0.8470 | AUC: 0.9470\n",
      "\n",
      "Best Inception model saved to: best_inceptionv3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\n===== EPOCH {epoch}/{NUM_EPOCHS} =====\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc, val_auc, report, cm, y_true, y_pred, y_probs = validate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | AUC: {val_auc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        print(f\"Improved {best_val_acc:.4f} → {val_acc:.4f}, saving model.\")\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "\n",
    "print(f\"\\nBest Inception model saved to: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e86a73",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6d50563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    matthews_corrcoef, cohen_kappa_score, precision_recall_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup\n",
    "NUM_CLASSES = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93798693",
   "metadata": {},
   "source": [
    "### ConvNeXt-Tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87f114f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.convnext_tiny(pretrained=True)\n",
    "model.classifier[2] = nn.Linear(model.classifier[2].in_features, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19af4993",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3da47315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, correct = 0.0, 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = correct / len(loader.dataset)\n",
    "    return avg_loss, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd5f17",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "17d38e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0.0, 0\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = correct / len(loader.dataset)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "    auc_score = roc_auc_score(y_true_bin, np.array(y_probs), multi_class='ovr')\n",
    "\n",
    "    report = classification_report(y_true, y_pred, digits=4)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return avg_loss, acc, auc_score, report, cm, y_true, y_pred, y_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f2dfc3",
   "metadata": {},
   "source": [
    "### Metrics Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8b18cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, y_probs):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "\n",
    "    kappa = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    macro_auc = roc_auc_score(y_true_bin, y_probs, average='macro', multi_class='ovr')\n",
    "    micro_auc = roc_auc_score(y_true_bin, y_probs, average='micro', multi_class='ovr')\n",
    "    weighted_auc = roc_auc_score(y_true_bin, y_probs, average='weighted', multi_class='ovr')\n",
    "\n",
    "    pr_aucs = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "        pr_aucs.append(auc(recall, precision))\n",
    "\n",
    "    auprc_macro = np.mean(pr_aucs)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    specificity = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
    "        fp = cm[:, i].sum() - cm[i, i]\n",
    "        specificity.append(tn / (tn + fp))\n",
    "\n",
    "    return {\n",
    "        \"Cohen_Kappa\": kappa,\n",
    "        \"MCC\": mcc,\n",
    "        \"AUC_Macro\": macro_auc,\n",
    "        \"AUC_Micro\": micro_auc,\n",
    "        \"AUC_Weighted\": weighted_auc,\n",
    "        \"AUPRC_Macro\": auprc_macro,\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"Confusion_Matrix\": cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c141d80",
   "metadata": {},
   "source": [
    "### Saving Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d0b8427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.6199 | Train Acc: 0.7648\n",
      "Val Loss: 0.6255 | Val Acc: 0.7568 | AUC: 0.9210\n",
      "Cohen’s Kappa: 0.8476 | MCC: 0.6452\n",
      "Macro AUC: 0.9210 | Micro AUC: 0.9499 | Weighted AUC: 0.9477\n",
      "AUPRC (Macro): 0.5968\n",
      "Class 0: Sensitivity = 0.9942, Specificity = 0.9742\n",
      "Class 1: Sensitivity = 0.2500, Specificity = 0.9939\n",
      "Class 2: Sensitivity = 0.6731, Specificity = 0.8740\n",
      "Class 3: Sensitivity = 0.6818, Specificity = 0.9186\n",
      "Class 4: Sensitivity = 0.3929, Specificity = 0.9379\n",
      "Validation accuracy improved (0.0000 --> 0.7568), saving model\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.4858 | Train Acc: 0.8096\n",
      "Val Loss: 0.4958 | Val Acc: 0.8306 | AUC: 0.9395\n",
      "Cohen’s Kappa: 0.8993 | MCC: 0.7537\n",
      "Macro AUC: 0.9395 | Micro AUC: 0.9711 | Weighted AUC: 0.9615\n",
      "AUPRC (Macro): 0.6918\n",
      "Class 0: Sensitivity = 0.9942, Specificity = 0.9948\n",
      "Class 1: Sensitivity = 0.4250, Specificity = 0.9877\n",
      "Class 2: Sensitivity = 0.9615, Specificity = 0.8130\n",
      "Class 3: Sensitivity = 0.0000, Specificity = 0.9971\n",
      "Class 4: Sensitivity = 0.5714, Specificity = 0.9793\n",
      "Validation accuracy improved (0.7568 --> 0.8306), saving model\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.4150 | Train Acc: 0.8369\n",
      "Val Loss: 0.5930 | Val Acc: 0.7869 | AUC: 0.9368\n",
      "Cohen’s Kappa: 0.8814 | MCC: 0.6859\n",
      "Macro AUC: 0.9368 | Micro AUC: 0.9594 | Weighted AUC: 0.9562\n",
      "AUPRC (Macro): 0.6836\n",
      "Class 0: Sensitivity = 0.9942, Specificity = 0.9639\n",
      "Class 1: Sensitivity = 0.0500, Specificity = 1.0000\n",
      "Class 2: Sensitivity = 0.8846, Specificity = 0.8244\n",
      "Class 3: Sensitivity = 0.2727, Specificity = 0.9767\n",
      "Class 4: Sensitivity = 0.6071, Specificity = 0.9497\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.3673 | Train Acc: 0.8577\n",
      "Val Loss: 0.4762 | Val Acc: 0.8251 | AUC: 0.9479\n",
      "Cohen’s Kappa: 0.9015 | MCC: 0.7426\n",
      "Macro AUC: 0.9479 | Micro AUC: 0.9738 | Weighted AUC: 0.9643\n",
      "AUPRC (Macro): 0.7313\n",
      "Class 0: Sensitivity = 0.9942, Specificity = 0.9845\n",
      "Class 1: Sensitivity = 0.3250, Specificity = 0.9847\n",
      "Class 2: Sensitivity = 0.9231, Specificity = 0.8244\n",
      "Class 3: Sensitivity = 0.2727, Specificity = 0.9855\n",
      "Class 4: Sensitivity = 0.5714, Specificity = 0.9852\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.3214 | Train Acc: 0.8857\n",
      "Val Loss: 0.4758 | Val Acc: 0.8361 | AUC: 0.9467\n",
      "Cohen’s Kappa: 0.9107 | MCC: 0.7616\n",
      "Macro AUC: 0.9467 | Micro AUC: 0.9742 | Weighted AUC: 0.9654\n",
      "AUPRC (Macro): 0.7341\n",
      "Class 0: Sensitivity = 0.9942, Specificity = 0.9897\n",
      "Class 1: Sensitivity = 0.4250, Specificity = 0.9908\n",
      "Class 2: Sensitivity = 0.9615, Specificity = 0.8168\n",
      "Class 3: Sensitivity = 0.0455, Specificity = 0.9942\n",
      "Class 4: Sensitivity = 0.6071, Specificity = 0.9852\n",
      "Validation accuracy improved (0.8306 --> 0.8361), saving model\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2924 | Train Acc: 0.8857\n",
      "Val Loss: 0.4718 | Val Acc: 0.8607 | AUC: 0.9517\n",
      "Cohen’s Kappa: 0.9054 | MCC: 0.7932\n",
      "Macro AUC: 0.9517 | Micro AUC: 0.9767 | Weighted AUC: 0.9676\n",
      "AUPRC (Macro): 0.7661\n",
      "Class 0: Sensitivity = 0.9942, Specificity = 0.9897\n",
      "Class 1: Sensitivity = 0.6250, Specificity = 0.9755\n",
      "Class 2: Sensitivity = 0.9038, Specificity = 0.8779\n",
      "Class 3: Sensitivity = 0.4091, Specificity = 0.9884\n",
      "Class 4: Sensitivity = 0.5714, Specificity = 0.9852\n",
      "Validation accuracy improved (0.8361 --> 0.8607), saving model\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2585 | Train Acc: 0.9058\n",
      "Val Loss: 0.5591 | Val Acc: 0.8361 | AUC: 0.9514\n",
      "Cohen’s Kappa: 0.8946 | MCC: 0.7626\n",
      "Macro AUC: 0.9514 | Micro AUC: 0.9754 | Weighted AUC: 0.9692\n",
      "AUPRC (Macro): 0.7560\n",
      "Class 0: Sensitivity = 0.9942, Specificity = 1.0000\n",
      "Class 1: Sensitivity = 0.4750, Specificity = 0.9847\n",
      "Class 2: Sensitivity = 0.9615, Specificity = 0.8053\n",
      "Class 3: Sensitivity = 0.0909, Specificity = 0.9971\n",
      "Class 4: Sensitivity = 0.5000, Specificity = 0.9911\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2425 | Train Acc: 0.9075\n",
      "Val Loss: 0.4987 | Val Acc: 0.8552 | AUC: 0.9497\n",
      "Cohen’s Kappa: 0.8993 | MCC: 0.7855\n",
      "Macro AUC: 0.9497 | Micro AUC: 0.9749 | Weighted AUC: 0.9660\n",
      "AUPRC (Macro): 0.7608\n",
      "Class 0: Sensitivity = 0.9884, Specificity = 0.9948\n",
      "Class 1: Sensitivity = 0.7250, Specificity = 0.9724\n",
      "Class 2: Sensitivity = 0.8750, Specificity = 0.8702\n",
      "Class 3: Sensitivity = 0.2727, Specificity = 0.9913\n",
      "Class 4: Sensitivity = 0.6071, Specificity = 0.9822\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2123 | Train Acc: 0.9195\n",
      "Val Loss: 0.5129 | Val Acc: 0.8497 | AUC: 0.9498\n",
      "Cohen’s Kappa: 0.9138 | MCC: 0.7781\n",
      "Macro AUC: 0.9498 | Micro AUC: 0.9765 | Weighted AUC: 0.9678\n",
      "AUPRC (Macro): 0.7606\n",
      "Class 0: Sensitivity = 0.9942, Specificity = 1.0000\n",
      "Class 1: Sensitivity = 0.5750, Specificity = 0.9816\n",
      "Class 2: Sensitivity = 0.9038, Specificity = 0.8550\n",
      "Class 3: Sensitivity = 0.2727, Specificity = 0.9826\n",
      "Class 4: Sensitivity = 0.6071, Specificity = 0.9852\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.1848 | Train Acc: 0.9355\n",
      "Val Loss: 0.5266 | Val Acc: 0.8497 | AUC: 0.9488\n",
      "Cohen’s Kappa: 0.9137 | MCC: 0.7782\n",
      "Macro AUC: 0.9488 | Micro AUC: 0.9766 | Weighted AUC: 0.9661\n",
      "AUPRC (Macro): 0.7425\n",
      "Class 0: Sensitivity = 0.9942, Specificity = 1.0000\n",
      "Class 1: Sensitivity = 0.6000, Specificity = 0.9755\n",
      "Class 2: Sensitivity = 0.9231, Specificity = 0.8588\n",
      "Class 3: Sensitivity = 0.1818, Specificity = 0.9884\n",
      "Class 4: Sensitivity = 0.5714, Specificity = 0.9822\n",
      "\n",
      "Best model saved to: best_model_convnext_tiny.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10  # Set as needed\n",
    "best_val_acc = 0.0  # Track the best validation accuracy\n",
    "best_model_path = \"saved_models/best_model_convnext_tiny.pth\"\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc, val_auc, report, cm, \\\n",
    "    y_true, y_pred, y_probs = validate(\n",
    "        model, val_loader, criterion\n",
    "    )\n",
    "\n",
    "    metrics = compute_metrics(y_true, y_pred, y_probs)\n",
    "\n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | AUC: {val_auc:.4f}\")\n",
    "    print(f\"Cohen’s Kappa: {metrics['Cohen_Kappa']:.4f} | MCC: {metrics['MCC']:.4f}\")\n",
    "    print(f\"Macro AUC: {metrics['AUC_Macro']:.4f} | Micro AUC: {metrics['AUC_Micro']:.4f} | \"\n",
    "          f\"Weighted AUC: {metrics['AUC_Weighted']:.4f}\")\n",
    "    print(f\"AUPRC (Macro): {metrics['AUPRC_Macro']:.4f}\")\n",
    "    for i in range(NUM_CLASSES):\n",
    "        print(f\"Class {i}: Sensitivity = {metrics['Sensitivity'][i]:.4f}, \"\n",
    "              f\"Specificity = {metrics['Specificity'][i]:.4f}\")\n",
    "\n",
    "    # Save model if validation accuracy improves\n",
    "    if val_acc > best_val_acc:\n",
    "        print(f\"Validation accuracy improved ({best_val_acc:.4f} --> {val_acc:.4f}), saving model\")\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "print(f\"\\nBest model saved to: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e45799",
   "metadata": {},
   "source": [
    "### Vision Transformer (ViT-B/16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cb16e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    precision_recall_curve, auc, cohen_kappa_score, matthews_corrcoef\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d988b",
   "metadata": {},
   "source": [
    "### CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48e5fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 10\n",
    "LR = 1e-4\n",
    "WD = 1e-4\n",
    "\n",
    "# Mixed precision scaler (updated API)\n",
    "scaler = torch.amp.GradScaler(device=\"cuda\")\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b216acf",
   "metadata": {},
   "source": [
    "### DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18616b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class APTOSDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.loc[idx, \"id_code\"]\n",
    "        label = int(self.df.loc[idx, \"diagnosis\"])\n",
    "\n",
    "        path = os.path.join(self.image_dir, f\"{img_id}.png\")\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7d566",
   "metadata": {},
   "source": [
    "### TRANSFORMS (224×224 for ViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c932ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8edff1f",
   "metadata": {},
   "source": [
    "### LOAD CSVs & SET IMAGE PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98f2ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"Dataset/train_1.csv\")\n",
    "val_df   = pd.read_csv(\"Dataset/valid.csv\")\n",
    "\n",
    "train_dir = \"Dataset/train_images\"\n",
    "val_dir   = \"Dataset/val_images\"\n",
    "\n",
    "train_dataset = APTOSDataset(train_df, train_dir, transform=train_transforms)\n",
    "val_dataset   = APTOSDataset(val_df, val_dir, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a88b3d",
   "metadata": {},
   "source": [
    "### MODEL: ViT-B/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac400481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B/16...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading ViT-B/16...\")\n",
    "\n",
    "model = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)\n",
    "model.heads.head = nn.Linear(model.heads.head.in_features, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e4fda7",
   "metadata": {},
   "source": [
    "### TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d833c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=f\"Training {epoch}\", leave=False):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        del images, labels, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = correct / len(loader.dataset)\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18928c4",
   "metadata": {},
   "source": [
    "### VALIDATION LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "025c08bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = probs.argmax(1)\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "            del images, labels, outputs, probs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss = running_loss / len(loader.dataset)\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "\n",
    "    # AUC\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "    auc_score = roc_auc_score(y_true_bin, np.array(y_probs), multi_class=\"ovr\")\n",
    "\n",
    "    # Confusion matrix + report\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, digits=4)\n",
    "\n",
    "    return avg_loss, accuracy, auc_score, report, cm, y_true, y_pred, y_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da8bb8d",
   "metadata": {},
   "source": [
    "### EXTRA METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bd1b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, y_probs):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "\n",
    "    kappa = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    macro_auc = roc_auc_score(y_true_bin, y_probs, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "    # AUPRC per class\n",
    "    pr_aucs = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        p, r, _ = precision_recall_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "        pr_aucs.append(auc(r, p))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    specificity = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
    "        fp = cm[:, i].sum() - cm[i, i]\n",
    "        specificity.append(tn / (tn + fp))\n",
    "\n",
    "    return {\n",
    "        \"Kappa\": kappa,\n",
    "        \"MCC\": mcc,\n",
    "        \"Macro_AUC\": macro_auc,\n",
    "        \"AUPRC_Macro\": np.mean(pr_aucs),\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"ConfusionMatrix\": cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb26e5cd",
   "metadata": {},
   "source": [
    "### TRAINING EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12fecaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Epoch 1/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9379 | Train Acc: 0.6703\n",
      "Val Loss:   0.8412 | Val Acc: 0.6995 | AUC: 0.8739\n",
      "Kappa: 0.7378430509965821 | MCC: 0.5750379138567142\n",
      "Improved 0.0000 → 0.6995. Saving model...\n",
      "\n",
      "===== Epoch 2/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7930 | Train Acc: 0.7106\n",
      "Val Loss:   0.8493 | Val Acc: 0.6940 | AUC: 0.8702\n",
      "Kappa: 0.6719908364885934 | MCC: 0.5270252012236379\n",
      "\n",
      "===== Epoch 3/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7445 | Train Acc: 0.7246\n",
      "Val Loss:   0.7642 | Val Acc: 0.7131 | AUC: 0.8891\n",
      "Kappa: 0.7130012557555463 | MCC: 0.560254877967469\n",
      "Improved 0.6995 → 0.7131. Saving model...\n",
      "\n",
      "===== Epoch 4/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7187 | Train Acc: 0.7290\n",
      "Val Loss:   0.6680 | Val Acc: 0.7404 | AUC: 0.8957\n",
      "Kappa: 0.7889996883764413 | MCC: 0.617808816658476\n",
      "Improved 0.7131 → 0.7404. Saving model...\n",
      "\n",
      "===== Epoch 5/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7127 | Train Acc: 0.7266\n",
      "Val Loss:   0.6385 | Val Acc: 0.7568 | AUC: 0.9119\n",
      "Kappa: 0.7995927999629818 | MCC: 0.6459722824501959\n",
      "Improved 0.7404 → 0.7568. Saving model...\n",
      "\n",
      "===== Epoch 6/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6649 | Train Acc: 0.7556\n",
      "Val Loss:   0.6193 | Val Acc: 0.7678 | AUC: 0.9142\n",
      "Kappa: 0.829498618239242 | MCC: 0.6610633711322322\n",
      "Improved 0.7568 → 0.7678. Saving model...\n",
      "\n",
      "===== Epoch 7/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6352 | Train Acc: 0.7584\n",
      "Val Loss:   0.7133 | Val Acc: 0.7268 | AUC: 0.8895\n",
      "Kappa: 0.7157375745526839 | MCC: 0.5912068379449216\n",
      "\n",
      "===== Epoch 8/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6261 | Train Acc: 0.7679\n",
      "Val Loss:   0.6550 | Val Acc: 0.7678 | AUC: 0.9059\n",
      "Kappa: 0.8531860327480766 | MCC: 0.6559150446594172\n",
      "\n",
      "===== Epoch 9/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6071 | Train Acc: 0.7737\n",
      "Val Loss:   0.7338 | Val Acc: 0.7322 | AUC: 0.9054\n",
      "Kappa: 0.823073890515882 | MCC: 0.6014713469114709\n",
      "\n",
      "===== Epoch 10/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5904 | Train Acc: 0.7792\n",
      "Val Loss:   0.5792 | Val Acc: 0.7951 | AUC: 0.9238\n",
      "Kappa: 0.8508360319873108 | MCC: 0.6997697175150761\n",
      "Improved 0.7678 → 0.7951. Saving model...\n",
      "\n",
      "Training complete. Best model saved to: best_vit_b16.pth\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "save_path = \"saved_models/best_vit_b16.pth\"\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\n===== Epoch {epoch}/{NUM_EPOCHS} =====\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, epoch)\n",
    "\n",
    "    val_loss, val_acc, val_auc, report, cm, y_true, y_pred, y_probs = validate(\n",
    "        model, val_loader, criterion\n",
    "    )\n",
    "\n",
    "    metrics = compute_metrics(y_true, y_pred, y_probs)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc: {val_acc:.4f} | AUC: {val_auc:.4f}\")\n",
    "    print(\"Kappa:\", metrics[\"Kappa\"], \"| MCC:\", metrics[\"MCC\"])\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        print(f\"Improved {best_acc:.4f} → {val_acc:.4f}. Saving model...\")\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print(f\"\\nTraining complete. Best model saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68355cad",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c929f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from sklearn.metrics import classification_report, confusion_matrix, \\\n",
    "    roc_auc_score, matthews_corrcoef, cohen_kappa_score, \\\n",
    "    precision_recall_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff057c1f",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7af4eb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /home/ubuntu/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 83.3M/83.3M [00:00<00:00, 143MB/s]\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 5\n",
    "NUM_EPOCHS=10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load ResNet34\n",
    "model = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=1e-4,\n",
    "                              weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2273d00a",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7cc88697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, correct = 0.0, 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = correct / len(loader.dataset)\n",
    "\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eb27d7",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4bff561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0.0, 0\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = correct / len(loader.dataset)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "    auc_score = roc_auc_score(y_true_bin, np.array(y_probs),\n",
    "                              multi_class='ovr')\n",
    "\n",
    "    report = classification_report(y_true, y_pred, digits=4)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return avg_loss, acc, auc_score, report, cm, \\\n",
    "           y_true, y_pred, y_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe2f3c",
   "metadata": {},
   "source": [
    "### Metrics Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff837f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, y_probs):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "\n",
    "    kappa = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    macro_auc = roc_auc_score(y_true_bin, y_probs,\n",
    "                              average='macro', multi_class='ovr')\n",
    "    micro_auc = roc_auc_score(y_true_bin, y_probs,\n",
    "                              average='micro', multi_class='ovr')\n",
    "    weighted_auc = roc_auc_score(y_true_bin, y_probs,\n",
    "                                 average='weighted', multi_class='ovr')\n",
    "\n",
    "    pr_aucs = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        precision, recall, _ = precision_recall_curve(y_true_bin[:, i],\n",
    "                                                      y_probs[:, i])\n",
    "        pr_aucs.append(auc(recall, precision))\n",
    "\n",
    "    auprc_macro = np.mean(pr_aucs)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    specificity = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
    "        fp = cm[:, i].sum() - cm[i, i]\n",
    "        specificity.append(tn / (tn + fp))\n",
    "\n",
    "    return {\n",
    "        \"Cohen_Kappa\": kappa,\n",
    "        \"MCC\": mcc,\n",
    "        \"AUC_Macro\": macro_auc,\n",
    "        \"AUC_Micro\": micro_auc,\n",
    "        \"AUC_Weighted\": weighted_auc,\n",
    "        \"AUPRC_Macro\": auprc_macro,\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"Confusion_Matrix\": cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe12df",
   "metadata": {},
   "source": [
    "### Saving Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "34d8c0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.0000 --> 0.7869), saving model\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.7869 --> 0.8279), saving model\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved (0.8279 --> 0.8361), saving model\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model saved to: best_model_resnet34.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "best_model_path = \"saved_models/best_model_resnet34.pth\"\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc, val_auc, report, cm, \\\n",
    "    y_true, y_pred, y_probs = validate(\n",
    "        model, val_loader, criterion\n",
    "    )\n",
    "\n",
    "    metrics = compute_metrics(y_true, y_pred, y_probs)\n",
    "\n",
    "    # Save model if validation accuracy improves\n",
    "    if val_acc > best_val_acc:\n",
    "        print(f\"Validation accuracy improved \"\n",
    "              f\"({best_val_acc:.4f} --> {val_acc:.4f}), saving model\")\n",
    "\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "print(f\"\\nBest model saved to: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ccefb",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6e640e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision.models import (\n",
    "    convnext_tiny, ConvNeXt_Tiny_Weights,\n",
    "    efficientnet_b0, EfficientNet_B0_Weights,\n",
    "    densenet121, DenseNet121_Weights,\n",
    "    vit_b_16, ViT_B_16_Weights\n",
    ")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3cedae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inceptionv3():\n",
    "    from torchvision import models\n",
    "\n",
    "    # Must enable aux_logits=True to create AuxLogits branch\n",
    "    model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT,\n",
    "                                 aux_logits=True)\n",
    "\n",
    "    # Replace both classifier heads to match the trained model\n",
    "    model.AuxLogits.fc = nn.Linear(model.AuxLogits.fc.in_features, NUM_CLASSES)\n",
    "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d6f16b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_convnext_tiny():\n",
    "    model = convnext_tiny(weights=ConvNeXt_Tiny_Weights.DEFAULT)\n",
    "    model.classifier[2] = nn.Linear(model.classifier[2].in_features, NUM_CLASSES)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cd6936b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_densenet121():\n",
    "    model = densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, NUM_CLASSES)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b5ab28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_efficientnet_b0():\n",
    "    model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "68e2743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vit_b16():\n",
    "    model = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)\n",
    "    model.heads.head = nn.Linear(model.heads.head.in_features, NUM_CLASSES)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "24f80a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet50():\n",
    "    from torchvision.models import resnet50, ResNet50_Weights\n",
    "    model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "05d9be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet34():\n",
    "    from torchvision.models import resnet34, ResNet34_Weights\n",
    "    model = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e367a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models = {\n",
    "    \"InceptionV3\": {\n",
    "        \"fn\": build_inceptionv3,\n",
    "        \"path\": \"saved_models/best_inceptionv3.pth\"\n",
    "    },\n",
    "    \"ConvNeXt-Tiny\": {\n",
    "        \"fn\": build_convnext_tiny,\n",
    "        \"path\": \"saved_models/best_model_convnext_tiny.pth\"\n",
    "    },\n",
    "    \"DenseNet121\": {\n",
    "        \"fn\": build_densenet121,\n",
    "        \"path\": \"saved_models/best_model_densenet121.pth\"\n",
    "    },\n",
    "    \"EfficientNet-B0\": {\n",
    "        \"fn\": build_efficientnet_b0,\n",
    "        \"path\": \"saved_models/best_model_efficientnet_b0_lowmem.pth\"\n",
    "    },\n",
    "    \"ViT-B16\": {\n",
    "        \"fn\": build_vit_b16,\n",
    "        \"path\": \"saved_models/best_vit_b16.pth\"\n",
    "    },\n",
    "    \"ResNet50\": {\n",
    "        \"fn\": build_resnet50,\n",
    "        \"path\": \"saved_models/best_model_resnet50.pth\"\n",
    "    },\n",
    "    \"ResNet34\": {\n",
    "        \"fn\": build_resnet34,\n",
    "        \"path\": \"saved_models/best_model_resnet34.pth\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b2bce5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_saved_model(model_name, model_fn, weights_path, val_loader, criterion):\n",
    "    print(f\"\\nEvaluating {model_name} ...\")\n",
    "\n",
    "    model = model_fn()\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    val_loss, val_acc, val_auc, report, cm, y_true, y_pred, y_probs = validate(\n",
    "        model, val_loader, criterion\n",
    "    )\n",
    "\n",
    "    metrics = compute_metrics(y_true, y_pred, y_probs)\n",
    "\n",
    "    return {\n",
    "    \"Accuracy\": val_acc,\n",
    "    \"AUC\": metrics.get(\"AUC_Macro\", metrics.get(\"AUC\", 0.0)),\n",
    "    \"Kappa\": metrics.get(\"Cohen_Kappa\", metrics.get(\"Kappa\", 0.0)),\n",
    "    \"MCC\": metrics.get(\"MCC\", 0.0)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6f0bd57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating InceptionV3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating ConvNeXt-Tiny ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating DenseNet121 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating EfficientNet-B0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating ViT-B16 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating ResNet50 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating ResNet34 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name, info in saved_models.items():\n",
    "    metrics = evaluate_saved_model(\n",
    "        model_name=name,\n",
    "        model_fn=info[\"fn\"],\n",
    "        weights_path=info[\"path\"],\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion\n",
    "    )\n",
    "    results[name] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750a276c",
   "metadata": {},
   "source": [
    "### Saving Model Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eae4aab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: model_comparison_report.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "summary_df = pd.DataFrame([\n",
    "{\n",
    "\"Model\": name,\n",
    "\"Accuracy\": results[name][\"Accuracy\"],\n",
    "\"AUC\": results[name][\"AUC\"],\n",
    "\"Kappa\": results[name][\"Kappa\"],\n",
    "\"MCC\": results[name][\"MCC\"]\n",
    "} for name in results\n",
    "])\n",
    "summary_df.to_csv(\"Results/model_comparison_report.csv\", index=False)\n",
    "print(\"\\nSaved: model_comparison_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57034e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
